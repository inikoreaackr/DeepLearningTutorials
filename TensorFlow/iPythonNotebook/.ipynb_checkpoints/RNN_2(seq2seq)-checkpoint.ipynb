{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network(RNN) \n",
    "\n",
    "\n",
    "Recurrent neural network(RNN)은 Text, 음성, 시계열 데이터등 순차적인(Sequential) 데이터들에 대한 분석을 할때 주로 사용하는 알고리즘입니다. <br>\n",
    "본 문서에서는 지난시간에 배웠던 RNN을 활용해 '임의의 순서'를 갖는 문자열 데이터로부터<br> 'I LOVE YOU'라는 순서를 갖는 문자열을 '나는 너를 사랑해'로 출력하는 RNN을 학습시켜 보겠습니다.<br>\n",
    "\n",
    "본 예제에서는<br>\n",
    "Input: ILOVEYOU -> Output: 나는너를사랑해 <br>\n",
    "되도록 학습 시킬 것 입니다.<br><br>\n",
    "이렇게 input과 output이 모두 Sequence인 모델을 <br>\n",
    "- sequence-to-sequence(seq2seq) \n",
    "- many-to-many model\n",
    "- encoder, decoder model\n",
    "\n",
    "이라고 부릅니다. 대표적인 예로는 Neural Machine Translation(NMT)가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-13T22:52:33.713489Z",
     "start_time": "2017-08-13T22:52:23.532102Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "import pprint #데이터를 보기 좋게 출력해주는 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자연어 처리에서는 보통 데이터를 다룰때 <br>\n",
    "1.단어사전) '텍스트데이터':'인덱스' <br>\n",
    "2.인덱스를 단어로변환) '인덱스':'텍스트데이터'<br>\n",
    "의 형태로 구축해서 사용합니다. <br>\n",
    "데이터를 처리할때 '텍스트데이터' 형태로 그대로 쓰기보다 '인덱스'를 사용해서 처리하는 것이 통상적이므로 여기서도 같은 방법을 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-13T22:52:33.732434Z",
     "start_time": "2017-08-13T22:52:33.714886Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Y': 5, 'V': 3, 'O': 2, 'I': 0, 'L': 1, 'U': 6, 'E': 4}\n",
      "{0: 'I', 1: 'L', 2: 'O', 3: 'V', 4: 'E', 5: 'Y', 6: 'U'}\n",
      "one_hot_dimension_en: 7\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "text_data_en = ['I','L','O','V','E','Y','O','U']\n",
    "\n",
    "# 단어사전 구축\n",
    "vocab_en = {}\n",
    "index_en = 0\n",
    "for text in text_data_en:\n",
    "    if text not in vocab_en:\n",
    "        vocab_en[text] = index_en\n",
    "        index_en = index_en + 1\n",
    "\n",
    "# 인덱스->단어 사전 구축\n",
    "index2Char_en = {}\n",
    "for text, index in vocab_en.items():\n",
    "    index2Char_en[index] = text\n",
    "\n",
    "print(vocab_en)\n",
    "print(index2Char_en)\n",
    "\n",
    "# one hot representation 차원 계산\n",
    "one_hot_dimension_en = len(vocab_en)\n",
    "print(\"one_hot_dimension_en:\", one_hot_dimension_en)\n",
    "\n",
    "# 넣어줄 데이터를 np.float32 타입으로 변환해줍니다. (지정하지 않아서 타입이 안맞을 경우 에러 발생)\n",
    "# 각 문자를 벡터로 나타내기 위해 one-hot representation 형태를 사용합니다.\n",
    "one_hot_embedding_matrix_en = np.array([[1, 0, 0, 0, 0, 0, 0],     # I\n",
    "                                       [0, 1, 0, 0, 0, 0, 0],  # L\n",
    "                                       [0, 0, 1, 0, 0, 0, 0],  # O\n",
    "                                       [0, 0, 0, 1, 0, 0, 0],  # V\n",
    "                                       [0, 0, 0, 0, 1, 0, 0],  # E\n",
    "                                       [0, 0, 0, 0, 0, 1, 0],  # Y\n",
    "                                       [0, 0, 0, 0, 0, 0, 1]], dtype=np.float32) # U\n",
    "\n",
    "print(one_hot_embedding_matrix_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-13T22:52:33.764191Z",
     "start_time": "2017-08-13T22:52:33.735833Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'랑': 5, '해': 6, '는': 1, '사': 4, '나': 0, '를': 3, '<eos>': 7, '너': 2}\n",
      "{0: '나', 1: '는', 2: '너', 3: '를', 4: '사', 5: '랑', 6: '해', 7: '<eos>'}\n",
      "one_hot_dimension_ko: 7\n"
     ]
    }
   ],
   "source": [
    "text_data_ko = ['나','는','너','를','사','랑','해', '<eos>']\n",
    "\n",
    "\n",
    "# 단어사전 구축\n",
    "vocab_ko = {}\n",
    "index_ko = 0\n",
    "for text in text_data_ko:\n",
    "    if text not in vocab_ko:\n",
    "        vocab_ko[text] = index_ko\n",
    "        index_ko = index_ko + 1\n",
    "\n",
    "# 인덱스->단어 사전 구축\n",
    "index2Char_ko = {}\n",
    "for text, index in vocab_ko.items():\n",
    "    index2Char_ko[index] = text\n",
    "\n",
    "print(vocab_ko)\n",
    "print(index2Char_ko)\n",
    "\n",
    "# one hot representation 차원 계산\n",
    "one_hot_dimension_ko = len(vocab_en)\n",
    "print(\"one_hot_dimension_ko:\", one_hot_dimension_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-13T22:52:37.139693Z",
     "start_time": "2017-08-13T22:52:37.121261Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_data [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "y_string ['나', '는', '너', '를', '사', '랑', '해', '<eos>']\n",
      "x_input_index [0, 1, 2, 3, 4, 5, 2, 6]\n",
      "x_input_string ['I', 'L', 'O', 'V', 'E', 'Y', 'O', 'U']\n",
      "x_input_one_hot\n",
      "[[[ 1.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  1.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  1.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  1.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  1.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  1.  0.]\n",
      "  [ 0.  0.  1.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  1.]]]\n"
     ]
    }
   ],
   "source": [
    "y_data = [[0, 1, 2, 3, 4, 5, 6, 7]]    # Target은 '나는너를사랑해<eos>' 입니다.\n",
    "y_string = [index2Char_ko[y] for y in y_data[0]]\n",
    "print(\"y_data\", y_data)\n",
    "print(\"y_string\", y_string)\n",
    "\n",
    "# 학습에 사용할 \"IILOVEYOU\"를 입력합니다.\n",
    "x_input_char = ['I','L','O','V','E','Y','O','U']\n",
    "\n",
    "# 문자열을 index로 바꾸겠습니다.\n",
    "x_input_index = []\n",
    "\n",
    "for x in x_input_char:    \n",
    "    x_input_index.append(vocab_en[x])  #  (문자->index) 로 변환\n",
    "\n",
    "print(\"x_input_index\", x_input_index)    \n",
    "x_input_string = [index2Char_en[x] for x in x_input_index]\n",
    "print(\"x_input_string\", x_input_string)\n",
    "\n",
    "# index를 이용하여 one_hot_vector 모양으로 바꾸겠습니다.\n",
    "x_input_one_hot = []\n",
    "for x in x_input_index:\n",
    "    x_input_one_hot.append(one_hot_embedding_matrix_en[x])\n",
    "x_input_one_hot = np.array([x_input_one_hot]) #TensorFlow에서는 첫차원이 Batch size이므로 차원을 한칸 밀어주기 위해 []를 추가합니다.\n",
    "print(\"x_input_one_hot\")\n",
    "print(x_input_one_hot) # Batch, 문장내 문자수, 문자 차원수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-13T22:52:38.212422Z",
     "start_time": "2017-08-13T22:52:38.206390Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "sequence_length = 8 #len(x_input_char)\n",
    "input_dimension = 7 #one_hot_dimension\n",
    "num_classes = 8 # 문자수\n",
    "hidden_size = 2 # RNN의 hidden layer 차원\n",
    "num_layers = 2 # Multi layer RNN의 layer 개수\n",
    "batch_size = 1 # 현재는 문장 1개로 하기 때문에 1\n",
    "learning_rate = 0.01 # Adam optimizer의 Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-13T22:52:39.756104Z",
     "start_time": "2017-08-13T22:52:39.747835Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_input = tf.placeholder(tf.float32, [None, sequence_length, input_dimension]) #Padding까지 고려된 크기\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length]) # RNN의 output은 character에 대한 index (Class 혹은 Label)\n",
    "seq_length = tf.placeholder(tf.int32) #나중에 가변적인 값을 넣을 때 사용 ex) [['really','good'],['good', 'pad']] 의 경우 Seq_length는 [2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-13T22:52:40.368155Z",
     "start_time": "2017-08-13T22:52:40.364175Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Bidirectional RNN\n",
    "지난 시간에 배운 Multi-Bidirectional RNN을 적용해보겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-13T22:52:41.551292Z",
     "start_time": "2017-08-13T22:52:41.534839Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Multi_Bi_RNN(x_input, sequence_length, hidden_size, num_layers, rnn_type='rnn'):\n",
    "    with tf.variable_scope('multi_bidirectional_rnn') as scope:\n",
    "        \n",
    "        \n",
    "        cell_fw = None\n",
    "        cell_bw = None\n",
    "        if(rnn_type == 'rnn'):\n",
    "            cell_fw = [tf.contrib.rnn.BasicRNNCell(num_units=hidden_size) for i in range(num_layers)]\n",
    "            cell_bw = [tf.contrib.rnn.BasicRNNCell(num_units=hidden_size) for i in range(num_layers)]\n",
    "            \n",
    "        elif(rnn_type == 'lstm'):\n",
    "            cell_fw = [tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True) for i in range(num_layers)]\n",
    "            cell_bw = [tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True) for i in range(num_layers)]\n",
    "            #state_is_tuple = True로 하면 Cell State와 Hidden State의 값을 tuple형태로 분리해서 보여줍니다.\n",
    "        cell_fw = tf.contrib.rnn.MultiRNNCell(cells=cell_fw, state_is_tuple=True)\n",
    "        cell_bw = tf.contrib.rnn.MultiRNNCell(cells=cell_bw, state_is_tuple=True)\n",
    "            \n",
    "        outputs, states = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, x_input, \n",
    "                                                          sequence_length=sequence_length,\n",
    "                                                          dtype=tf.float32)\n",
    "        return outputs, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-13T22:52:42.760768Z",
     "start_time": "2017-08-13T22:52:42.120313Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs, states = Multi_Bi_RNN(X_input, seq_length, hidden_size, num_layers, rnn_type='lstm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layer\n",
    "RNN에서 나온 값들을 Fully Connected Layer의 Input 값으로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-13T22:52:43.941406Z",
     "start_time": "2017-08-13T22:52:43.884121Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x_for_fc_0 = tf.reshape(outputs[0], [-1, hidden_size])\n",
    "# x_for_fc_1 = tf.reshape(outputs[1], [-1, hidden_size])\n",
    "# x_for_fc = tf.concat(x_for_fc_0, x_for_fc_1, axis = 1)\n",
    "\n",
    "x_for_fc = tf.reshape(outputs, [-1, hidden_size * 2]) # Bidirectional 이기 때문에 Output이 2개 나오기 때문에 hidden_size * 2\n",
    "\n",
    "outputs = tf.contrib.layers.fully_connected(\n",
    "    inputs=x_for_fc, num_outputs=num_classes, activation_fn=None, weights_initializer=tf.contrib.layers.xavier_initializer()) # Xavier Glorot and Yoshua Bengio (2010): Understanding the difficulty of training deep feedforward neural networks. \n",
    "#print(outputs) #Tensor(\"fully_connected/BiasAdd:0\", shape=(?, 7), dtype=float32)\n",
    "\n",
    "outputs = tf.reshape(outputs, [batch_size, sequence_length, num_classes]) #TODO Seq_length\n",
    "#print(outputs) #Tensor(\"Reshape_2:0\", shape=(1, 8, 7), dtype=float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq Loss 계산 및 Train op\n",
    "Time Step 마다 나오는 output과 거기에 대응되는 Target Y의 loss를 계산해줍니다.<br>\n",
    "Tensorflow에서는 이를 위한 API인 tf.contrib.seq2seq.sequence_loss를 제공해줍니다.<br>\n",
    "weights는 주로 padding이 있을때 masking 용도로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-13T22:52:46.935276Z",
     "start_time": "2017-08-13T22:52:45.091855Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = tf.ones([batch_size, sequence_length])\n",
    "\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "    logits=outputs, targets=Y, weights=weights)\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-13T22:52:46.946329Z",
     "start_time": "2017-08-13T22:52:46.937123Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax(outputs, axis=2) # 0: Batch_size, 1: Sequence_length, 2: Num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-13T22:52:48.861782Z",
     "start_time": "2017-08-13T22:52:47.900217Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Evaluation\n",
    "정의한 Operation을 session에 넣고 training을 시작합니다.<br>\n",
    "모델이 예측하는 문자열의 순서를 확인합니다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-13T22:52:57.086245Z",
     "start_time": "2017-08-13T22:52:49.689082Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 2.07264 prediction:  [[3 3 3 3 0 0 0 0]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를나나나나\n",
      "1 loss: 2.06585 prediction:  [[3 3 3 3 0 0 0 0]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를나나나나\n",
      "2 loss: 2.05838 prediction:  [[3 3 3 3 0 0 0 0]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를나나나나\n",
      "3 loss: 2.05022 prediction:  [[3 3 3 3 0 0 0 0]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를나나나나\n",
      "4 loss: 2.04139 prediction:  [[3 3 3 3 0 0 0 0]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를나나나나\n",
      "5 loss: 2.0319 prediction:  [[3 3 3 3 0 0 0 0]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를나나나나\n",
      "6 loss: 2.02178 prediction:  [[3 3 3 3 0 0 0 0]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를나나나나\n",
      "7 loss: 2.01104 prediction:  [[3 3 3 3 0 0 0 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를나나나랑\n",
      "8 loss: 1.99968 prediction:  [[3 3 3 3 0 0 0 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를나나나랑\n",
      "9 loss: 1.98774 prediction:  [[3 3 3 3 0 0 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를나나사랑\n",
      "10 loss: 1.97523 prediction:  [[3 3 3 3 0 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를나사사랑\n",
      "11 loss: 1.96218 prediction:  [[3 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를사사사랑\n",
      "12 loss: 1.9486 prediction:  [[3 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를사사사랑\n",
      "13 loss: 1.93451 prediction:  [[3 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를사사사랑\n",
      "14 loss: 1.9199 prediction:  [[3 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를사사사랑\n",
      "15 loss: 1.90476 prediction:  [[3 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를사사사랑\n",
      "16 loss: 1.88907 prediction:  [[3 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를사사사랑\n",
      "17 loss: 1.87282 prediction:  [[3 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를사사사랑\n",
      "18 loss: 1.856 prediction:  [[3 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를사사사랑\n",
      "19 loss: 1.83863 prediction:  [[3 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를사사사랑\n",
      "20 loss: 1.82076 prediction:  [[3 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를사사사랑\n",
      "21 loss: 1.80247 prediction:  [[3 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를사사사랑\n",
      "22 loss: 1.78389 prediction:  [[3 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  를를를를사사사랑\n",
      "23 loss: 1.76516 prediction:  [[2 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  너를를를사사사랑\n",
      "24 loss: 1.74642 prediction:  [[2 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  너를를를사사사랑\n",
      "25 loss: 1.72781 prediction:  [[2 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  너를를를사사사랑\n",
      "26 loss: 1.7094 prediction:  [[2 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  너를를를사사사랑\n",
      "27 loss: 1.69126 prediction:  [[2 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  너를를를사사사랑\n",
      "28 loss: 1.67339 prediction:  [[2 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  너를를를사사사랑\n",
      "29 loss: 1.65573 prediction:  [[2 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  너를를를사사사랑\n",
      "30 loss: 1.6382 prediction:  [[2 3 3 3 4 4 4 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  너를를를사사사랑\n",
      "31 loss: 1.62068 prediction:  [[2 3 3 3 4 4 5 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  너를를를사사랑랑\n",
      "32 loss: 1.60309 prediction:  [[2 3 3 3 4 4 5 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  너를를를사사랑랑\n",
      "33 loss: 1.58534 prediction:  [[2 3 3 3 4 5 5 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  너를를를사랑랑랑\n",
      "34 loss: 1.56743 prediction:  [[2 3 3 3 4 5 5 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  너를를를사랑랑랑\n",
      "35 loss: 1.54939 prediction:  [[2 3 3 3 5 5 5 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  너를를를랑랑랑랑\n",
      "36 loss: 1.53124 prediction:  [[2 3 3 3 5 5 5 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  너를를를랑랑랑랑\n",
      "37 loss: 1.51302 prediction:  [[2 3 3 3 5 5 5 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  너를를를랑랑랑랑\n",
      "38 loss: 1.49472 prediction:  [[2 2 3 3 5 5 5 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  너너를를랑랑랑랑\n",
      "39 loss: 1.47636 prediction:  [[2 2 3 3 5 5 5 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  너너를를랑랑랑랑\n",
      "40 loss: 1.45793 prediction:  [[0 2 3 3 5 5 5 5]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나너를를랑랑랑랑\n",
      "41 loss: 1.43939 prediction:  [[0 2 3 3 5 5 5 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나너를를랑랑랑해\n",
      "42 loss: 1.42075 prediction:  [[0 2 3 3 5 5 5 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나너를를랑랑랑해\n",
      "43 loss: 1.40207 prediction:  [[0 2 3 3 4 5 5 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나너를를사랑랑해\n",
      "44 loss: 1.38339 prediction:  [[0 2 3 3 4 5 5 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나너를를사랑랑해\n",
      "45 loss: 1.3648 prediction:  [[0 2 3 3 4 5 5 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나너를를사랑랑해\n",
      "46 loss: 1.34632 prediction:  [[0 2 3 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나너를를사랑해해\n",
      "47 loss: 1.32794 prediction:  [[0 2 3 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나너를를사랑해해\n",
      "48 loss: 1.30959 prediction:  [[0 1 3 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는를를사랑해해\n",
      "49 loss: 1.29122 prediction:  [[0 1 3 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는를를사랑해해\n",
      "50 loss: 1.27283 prediction:  [[0 1 3 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는를를사랑해해\n",
      "51 loss: 1.25445 prediction:  [[0 1 3 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는를를사랑해해\n",
      "52 loss: 1.23607 prediction:  [[0 1 3 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는를를사랑해해\n",
      "53 loss: 1.21764 prediction:  [[0 1 3 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는를를사랑해해\n",
      "54 loss: 1.19908 prediction:  [[0 1 3 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는를를사랑해해\n",
      "55 loss: 1.18044 prediction:  [[0 1 3 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는를를사랑해해\n",
      "56 loss: 1.16177 prediction:  [[0 1 3 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는를를사랑해해\n",
      "57 loss: 1.14311 prediction:  [[0 1 3 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는를를사랑해해\n",
      "58 loss: 1.12444 prediction:  [[0 1 3 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는를를사랑해해\n",
      "59 loss: 1.10578 prediction:  [[0 1 3 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는를를사랑해해\n",
      "60 loss: 1.08721 prediction:  [[0 1 3 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는를를사랑해해\n",
      "61 loss: 1.0688 prediction:  [[0 1 2 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해해\n",
      "62 loss: 1.05056 prediction:  [[0 1 2 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해해\n",
      "63 loss: 1.03252 prediction:  [[0 1 2 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해해\n",
      "64 loss: 1.01474 prediction:  [[0 1 2 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해해\n",
      "65 loss: 0.997277 prediction:  [[0 1 2 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해해\n",
      "66 loss: 0.980136 prediction:  [[0 1 2 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해해\n",
      "67 loss: 0.963324 prediction:  [[0 1 2 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해해\n",
      "68 loss: 0.946887 prediction:  [[0 1 2 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해해\n",
      "69 loss: 0.930822 prediction:  [[0 1 2 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해해\n",
      "70 loss: 0.915099 prediction:  [[0 1 2 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해해\n",
      "71 loss: 0.899733 prediction:  [[0 1 2 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해해\n",
      "72 loss: 0.884732 prediction:  [[0 1 2 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해해\n",
      "73 loss: 0.870058 prediction:  [[0 1 2 3 4 5 6 6]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해해\n",
      "74 loss: 0.855713 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "75 loss: 0.841703 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "76 loss: 0.827994 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "77 loss: 0.814585 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "78 loss: 0.801481 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "79 loss: 0.788654 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "80 loss: 0.776108 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "81 loss: 0.76384 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "82 loss: 0.75183 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "83 loss: 0.740086 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "84 loss: 0.728597 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "85 loss: 0.717355 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "86 loss: 0.706365 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "87 loss: 0.69561 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "88 loss: 0.685092 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "89 loss: 0.674805 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "90 loss: 0.664739 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "91 loss: 0.654894 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "92 loss: 0.645256 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "93 loss: 0.635824 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "94 loss: 0.62659 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "95 loss: 0.617547 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "96 loss: 0.608692 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "97 loss: 0.600015 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "98 loss: 0.591515 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "99 loss: 0.583185 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "100 loss: 0.57502 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "101 loss: 0.567019 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "102 loss: 0.559173 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "103 loss: 0.551483 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "104 loss: 0.543942 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "105 loss: 0.536549 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "106 loss: 0.529299 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "107 loss: 0.522188 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "108 loss: 0.515213 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "109 loss: 0.508371 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "110 loss: 0.501658 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "111 loss: 0.495071 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "112 loss: 0.488606 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "113 loss: 0.48226 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "114 loss: 0.476028 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "115 loss: 0.46991 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "116 loss: 0.4639 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "117 loss: 0.457996 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "118 loss: 0.452196 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "119 loss: 0.446496 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "120 loss: 0.440895 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "121 loss: 0.43539 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "122 loss: 0.429979 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "123 loss: 0.424659 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "124 loss: 0.41943 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "125 loss: 0.414288 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "126 loss: 0.409233 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "127 loss: 0.404262 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "128 loss: 0.399374 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "129 loss: 0.394567 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "130 loss: 0.38984 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "131 loss: 0.38519 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "132 loss: 0.380617 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "133 loss: 0.376118 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "134 loss: 0.371693 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "135 loss: 0.36734 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "136 loss: 0.363057 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "137 loss: 0.358843 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "138 loss: 0.354697 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "139 loss: 0.350618 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "140 loss: 0.346604 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "141 loss: 0.342654 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "142 loss: 0.338767 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "143 loss: 0.334942 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "144 loss: 0.331178 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "145 loss: 0.327473 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "146 loss: 0.323827 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "147 loss: 0.320239 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "148 loss: 0.316708 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "149 loss: 0.313232 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "150 loss: 0.309811 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "151 loss: 0.306443 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "152 loss: 0.303129 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "153 loss: 0.299866 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "154 loss: 0.296654 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "155 loss: 0.293492 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "156 loss: 0.29038 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "157 loss: 0.287315 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "158 loss: 0.284298 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "159 loss: 0.281328 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "160 loss: 0.278403 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "161 loss: 0.275523 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "162 loss: 0.272687 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "163 loss: 0.269894 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "164 loss: 0.267144 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "165 loss: 0.264436 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "166 loss: 0.261768 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "167 loss: 0.259141 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "168 loss: 0.256553 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "169 loss: 0.254004 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "170 loss: 0.251493 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "171 loss: 0.24902 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "172 loss: 0.246583 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "173 loss: 0.244182 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "174 loss: 0.241817 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "175 loss: 0.239487 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "176 loss: 0.237191 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "177 loss: 0.234928 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "178 loss: 0.232698 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "179 loss: 0.230501 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "180 loss: 0.228335 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "181 loss: 0.226201 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "182 loss: 0.224097 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "183 loss: 0.222024 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "184 loss: 0.21998 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "185 loss: 0.217965 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "186 loss: 0.215978 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "187 loss: 0.214019 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "188 loss: 0.212088 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "189 loss: 0.210184 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "190 loss: 0.208306 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "191 loss: 0.206455 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "192 loss: 0.204628 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "193 loss: 0.202827 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "194 loss: 0.201051 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "195 loss: 0.199298 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "196 loss: 0.19757 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "197 loss: 0.195865 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "198 loss: 0.194182 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "199 loss: 0.192523 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "200 loss: 0.190885 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "201 loss: 0.189269 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "202 loss: 0.187674 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "203 loss: 0.186101 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "204 loss: 0.184547 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "205 loss: 0.183015 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "206 loss: 0.181502 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "207 loss: 0.180008 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "208 loss: 0.178534 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "209 loss: 0.177079 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "210 loss: 0.175642 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "211 loss: 0.174223 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "212 loss: 0.172823 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "213 loss: 0.171439 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "214 loss: 0.170074 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "215 loss: 0.168725 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "216 loss: 0.167393 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "217 loss: 0.166078 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "218 loss: 0.164778 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "219 loss: 0.163495 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "220 loss: 0.162227 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "221 loss: 0.160975 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "222 loss: 0.159738 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "223 loss: 0.158516 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "224 loss: 0.157309 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "225 loss: 0.156115 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "226 loss: 0.154937 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "227 loss: 0.153772 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "228 loss: 0.152621 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "229 loss: 0.151483 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "230 loss: 0.150359 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "231 loss: 0.149248 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "232 loss: 0.14815 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "233 loss: 0.147065 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "234 loss: 0.145992 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "235 loss: 0.144931 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "236 loss: 0.143883 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "237 loss: 0.142846 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "238 loss: 0.141822 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "239 loss: 0.140809 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "240 loss: 0.139807 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "241 loss: 0.138816 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "242 loss: 0.137837 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "243 loss: 0.136869 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "244 loss: 0.135911 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "245 loss: 0.134964 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "246 loss: 0.134027 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "247 loss: 0.133101 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "248 loss: 0.132185 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "249 loss: 0.131279 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "250 loss: 0.130382 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "251 loss: 0.129495 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "252 loss: 0.128618 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "253 loss: 0.127751 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "254 loss: 0.126892 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "255 loss: 0.126043 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "256 loss: 0.125203 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "257 loss: 0.124371 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "258 loss: 0.123549 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "259 loss: 0.122735 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "260 loss: 0.121929 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "261 loss: 0.121132 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "262 loss: 0.120344 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "263 loss: 0.119563 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "264 loss: 0.118791 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "265 loss: 0.118026 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "266 loss: 0.117269 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "267 loss: 0.11652 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "268 loss: 0.115779 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "269 loss: 0.115045 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "270 loss: 0.114319 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "271 loss: 0.113599 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "272 loss: 0.112887 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "273 loss: 0.112183 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "274 loss: 0.111485 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "275 loss: 0.110794 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "276 loss: 0.11011 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "277 loss: 0.109433 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "278 loss: 0.108762 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "279 loss: 0.108098 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "280 loss: 0.10744 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "281 loss: 0.106789 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "282 loss: 0.106144 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "283 loss: 0.105506 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "284 loss: 0.104873 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "285 loss: 0.104247 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "286 loss: 0.103626 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "287 loss: 0.103012 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "288 loss: 0.102403 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "289 loss: 0.1018 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "290 loss: 0.101203 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "291 loss: 0.100611 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "292 loss: 0.100025 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "293 loss: 0.0994443 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "294 loss: 0.0988691 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "295 loss: 0.0982992 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "296 loss: 0.0977346 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "297 loss: 0.0971751 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "298 loss: 0.0966209 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "299 loss: 0.0960716 prediction:  [[0 1 2 3 4 5 6 7]] true Y:  [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "RNN 모델의 예측 결과:  나는너를사랑해<eos>\n",
      "End:)\n"
     ]
    }
   ],
   "source": [
    "for i in range(300):\n",
    "        l, _ = sess.run([loss, train], feed_dict={X_input: x_input_one_hot, Y: y_data, seq_length:[8]}) # seq_length:[sequence_length] (Batch_size, Seq)\n",
    "        result = sess.run(prediction, feed_dict={X_input: x_input_one_hot, seq_length:[8]})\n",
    "        print(i, \"loss:\", l, \"prediction: \", result, \"true Y: \", y_data)\n",
    "\n",
    "        # print char using dic\n",
    "        result_str = [index2Char_ko[c] for c in np.squeeze(result)]\n",
    "        print(\"RNN 모델의 예측 결과: \", ''.join(result_str))\n",
    "print(\"End:)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
